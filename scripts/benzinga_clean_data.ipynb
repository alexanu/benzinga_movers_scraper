{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from pandas.tseries.offsets import BDay\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('stock_headlines.csv')\n",
    "prices = pd.read_csv('stock_prices.csv')\n",
    "volumes = pd.read_csv('stock_volumes.csv')\n",
    "filings = pd.read_csv('filing_dates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(pd.to_datetime(df.date).dt.date)\n",
    "prices['date'] = pd.to_datetime(prices.date)\n",
    "volumes['date'] = pd.to_datetime(volumes.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get closing price day of headline\n",
    "df2 = pd.merge(df, prices, on = ['ticker', 'date'], how = 'left', copy = False)\n",
    "df2 = df2.rename(columns = {'close':'cur_day_close'})\n",
    "\n",
    "#if cur_day_close is null, date might be on a holiday, offset those dates by 1 business day and try again\n",
    "df2.loc[df2.cur_day_close.isnull(), 'date'] = df2.date - BDay(1)\n",
    "df2 = pd.merge(df2, prices, on = ['ticker', 'date'], how = 'left', copy = False)\n",
    "\n",
    "df2.loc[df2.cur_day_close.isnull(), 'cur_day_close'] = df2.close\n",
    "del df2['close']\n",
    "\n",
    "#remove rows where we do not have price data for on that date\n",
    "df2 = df2[df2.cur_day_close.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove rows with < 20 days of trading days\n",
    "price_max_dates = prices.pivot_table(index = 'ticker', values = 'date', aggfunc = 'max').reset_index()\n",
    "price_max_dates.columns = ['ticker', 'max_date']\n",
    "df2 = pd.merge(df2, price_max_dates, on = 'ticker', how = 'left', copy = False)\n",
    "df2 = df2[df2.date < df2.max_date - BDay(20)]\n",
    "\n",
    "del df2['max_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get previous day's close\n",
    "df2 = df2.sort_values('date', ascending = True)\n",
    "prices = prices.sort_values('date', ascending = True)\n",
    "\n",
    "df2 = pd.merge_asof(df2, prices, by = 'ticker', left_on = 'date', right_on = 'date', direction = 'backward',\n",
    "                    allow_exact_matches = False)\n",
    "\n",
    "df2 = df2.rename(columns = {'close':'prev_day_close'})\n",
    "\n",
    "#remove rows where we do not have price data on that previous date\n",
    "df2 = df2[df2.prev_day_close.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate 10, 20, 50, 200 price price_dma\n",
    "prices['price_5_dma'] = prices.groupby('ticker').close.rolling(5).mean().reset_index(0, drop = True)\n",
    "prices['price_10_dma'] = prices.groupby('ticker').close.rolling(10).mean().reset_index(0, drop = True)\n",
    "prices['price_20_dma'] = prices.groupby('ticker').close.rolling(20).mean().reset_index(0, drop = True)\n",
    "prices['price_50_dma'] = prices.groupby('ticker').close.rolling(50).mean().reset_index(0, drop = True)\n",
    "prices['price_100_dma'] = prices.groupby('ticker').close.rolling(100).mean().reset_index(0, drop = True)\n",
    "prices['price_200_dma'] = prices.groupby('ticker').close.rolling(200).mean().reset_index(0, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join price price_dma to headlines\n",
    "df2 = pd.merge(df2, prices[['ticker', 'date', 'price_5_dma','price_10_dma', 'price_20_dma', 'price_50_dma', 'price_100_dma','price_200_dma']],\n",
    "               on = ['ticker', 'date'], how = 'left', copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get price volumes day of headline\n",
    "df2 = pd.merge(df2, volumes, on = ['ticker', 'date'], how = 'left', copy = False)\n",
    "df2 = df2.rename(columns = {'volume':'cur_day_volume'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get previous day's volume\n",
    "df2 = df2.sort_values('date', ascending = True)\n",
    "volumes = volumes.sort_values('date', ascending = True)\n",
    "\n",
    "df2 = pd.merge_asof(df2, volumes, by = 'ticker', left_on = 'date', right_on = 'date', direction = 'backward',\n",
    "                    allow_exact_matches = False)\n",
    "\n",
    "df2 = df2.rename(columns = {'volume':'prev_day_volume'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate 10, 20, 50, 200 volume volume_dma\n",
    "volumes['volume_5_dma'] = volumes.groupby('ticker').volume.rolling(5).mean().reset_index(0, drop = True)\n",
    "volumes['volume_10_dma'] = volumes.groupby('ticker').volume.rolling(10).mean().reset_index(0, drop = True)\n",
    "volumes['volume_20_dma'] = volumes.groupby('ticker').volume.rolling(20).mean().reset_index(0, drop = True)\n",
    "volumes['volume_50_dma'] = volumes.groupby('ticker').volume.rolling(50).mean().reset_index(0, drop = True)\n",
    "volumes['volume_100_dma'] = volumes.groupby('ticker').volume.rolling(100).mean().reset_index(0, drop = True)\n",
    "volumes['volume_200_dma'] = volumes.groupby('ticker').volume.rolling(200).mean().reset_index(0, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join volume_dma to headlines\n",
    "df2 = pd.merge(df2, volumes[['ticker', 'date', 'volume_5_dma','volume_10_dma', 'volume_20_dma', 'volume_50_dma', 'volume_100_dma','volume_200_dma']],\n",
    "               on = ['ticker', 'date'], how = 'left', copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get % price movement from previous day\n",
    "df2['price_move'] = (df2.cur_day_close - df2.prev_day_close) / df2.prev_day_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_copy = df2.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2_copy.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get price after 19 days from current headline date (20 trading days from previous close date)\n",
    "df2['end_date'] = df2.date + BDay(19)\n",
    "df2 = pd.merge_asof(df2, prices[['ticker', 'date', 'close']], by = 'ticker', left_on = 'end_date', right_on = 'date', direction = 'forward',\n",
    "                    allow_exact_matches = True)\n",
    "\n",
    "del df2['end_date']\n",
    "del df2['date_y']\n",
    "\n",
    "df2 = df2.rename(columns = {'date_x':'date', 'close':'period_end_close'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save dataframe of cleaned stock headlines\n",
    "df2.to_csv('stock_headlines_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
